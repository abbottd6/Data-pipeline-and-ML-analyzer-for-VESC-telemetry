{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4628caaa-c3d6-483e-91bf-540827e437c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dayto\\AppData\\Local\\Temp\\ipykernel_24216\\912693871.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"best_model.pt\", map_location=DEVICE)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# ---------------------- SETUP AND IMPORTS ----------------------------------------------------------------------------\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ipywidgets import FileUpload, Dropdown, SelectMultiple, Button, VBox, HBox, Output, IntSlider, Checkbox\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# import the dataset\n",
    "from model.vesc_dataset import VESCTimeSeriesDataset, VESCDatasetConfig, CONFIDENCE_COLS, FEATURE_COLS\n",
    "from preprocessing.prod_preprocessing import prod_load_log, prod_sample_rate_normalization\n",
    "from preprocessing.training_preprocessing import infer_log_date_from_filename\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(c_in, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "        )\n",
    "        self.head = nn.Linear(64, c_out)\n",
    "\n",
    "    # x: (B, T, C)\n",
    "    def forward(self, x):\n",
    "        # translate to (B, C, T)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        h = self.net(x).squeeze(-1)\n",
    "        # (B, C_out) logits\n",
    "        return self.head(h)\n",
    "\n",
    "# load normalization stats from npz\n",
    "STATS = np.load(\"norm_stats.npz\", allow_pickle=True)\n",
    "MEAN = torch.from_numpy(STATS[\"mean\"]).to(DEVICE)\n",
    "STD = torch.from_numpy(STATS[\"std\"]).to(DEVICE)\n",
    "FEATURE_COLS = list(STATS[\"feature_cols\"])\n",
    "\n",
    "# normalize the batches to comparable value scale\n",
    "def normalize_batch(xb: torch.Tensor) -> torch.Tensor:\n",
    "    return (xb - MEAN) / STD\n",
    "\n",
    "# load trained model\n",
    "def load_model():\n",
    "    c_in = len(FEATURE_COLS)\n",
    "    C_out = len(CONFIDENCE_COLS)\n",
    "    model = CNN(c_in, C_out).to(DEVICE)\n",
    "    state = torch.load(\"best_model.pt\", map_location=DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "MODEL = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4bce58-2a7a-4614-983d-cd037e93994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# ---------------------- LOG FILE PREPROCESSING -----------------------------------------------------------------------\n",
    "\n",
    "from preprocessing import prod_preprocessing\n",
    "\n",
    "# Input: path to a raw CSV uploaded by the user\n",
    "# Output: path to a single processed CSV (with your columns)\n",
    "def preprocess_user_log(raw_csv_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert a raw VESC Tool ride log into a CSV formatted for the machine learning model.\n",
    "    Return the path to the processed CSV.\n",
    "    \"\"\"\n",
    "    raw_path = Path(raw_csv_path)\n",
    "    # infer log date\n",
    "    ride_date = infer_log_date_from_filename(raw_csv_path)\n",
    "\n",
    "    # load the log\n",
    "    df = prod_load_log(raw_path, ride_date)\n",
    "    df_resampled =  prod_sample_rate_normalization(df)\n",
    "\n",
    "    out_dir = Path(\"tmp_processed\")\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    out_path = out_dir / f\"{raw_path.stem}_processed.csv\"\n",
    "    df_resampled.to_csv(out_path, index=False)\n",
    "    return str(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de36845b-1992-4faa-8687-c8df91a54486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# ---------------------- MODEL INFERENCE AND TIMELINE PLOTTING --------------------------------------------------------\n",
    "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
    "\n",
    "def build_dataset_from_csv(csv_path: str) -> VESCTimeSeriesDataset:\n",
    "    cfg = VESCDatasetConfig(\n",
    "        files=[csv_path],\n",
    "        feature_cols=None,\n",
    "        conf_cols=None,\n",
    "        sampling_hz=10.0,\n",
    "        window_ms=3000,\n",
    "        stride_ms=500,\n",
    "        min_valid_ratio=0.7,\n",
    "    )\n",
    "    ds = VESCTimeSeriesDataset(cfg)\n",
    "    # store the source path\n",
    "    ds._dfs[0].attrs[\"_source_path\"] = str(csv_path)\n",
    "    return ds\n",
    "\n",
    "def run_inference_on_dataset(ds: VESCTimeSeriesDataset):\n",
    "    # collect windows for file 0, sorted by start index\n",
    "    idxs = [(k, s, e) for k,(fi,s,e) in enumerate(ds._index) if fi == 0]\n",
    "    idxs.sort(key=lambda t: t[1])\n",
    "\n",
    "    df = ds._dfs[0]\n",
    "    tcol = ds.cfg.time_col if ds.cfg.time_col in df.columns else None\n",
    "\n",
    "    preds = []\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for k, s, e in idxs:\n",
    "            X, _ = ds[k]                              # (T,Cin), (Cout,)\n",
    "            xb = X.unsqueeze(0).to(DEVICE)            # (1,T,Cin)\n",
    "            pb = torch.sigmoid(MODEL(normalize_batch(xb))).cpu().numpy()[0]\n",
    "            preds.append(pb)\n",
    "            t_mid = float(df.loc[s:e-1, tcol].median()) if tcol else float(s)\n",
    "            times.append(t_mid)\n",
    "\n",
    "    preds = np.vstack(preds)     # (N, C_out)\n",
    "    times = np.asarray(times)    # (N,)\n",
    "    # normalize time to seconds starting at 0\n",
    "    t0 = times.min()\n",
    "    tsec = (times - t0) / 1000.0\n",
    "    # bar width (seconds)\n",
    "    win_sec = ds.window_steps / ds.cfg.sampling_hz\n",
    "    return tsec, win_sec, preds\n",
    "\n",
    "def _fmt_mmss(x, pos=None):\n",
    "    m = int(x // 60)\n",
    "    s = int(x % 60)\n",
    "    return f\"{m}:{s:02d}\"\n",
    "\n",
    "def plot_timeline_bars(\n",
    "    tsec, win_sec, preds, targets, CONFIDENCE_COLS, selected,\n",
    "    alpha=0.35, stack=False, \n",
    "    xlim=None, x_tick=5, ylim_max=1.0, y_tick=0.1, decimate=1, stride_sec=None\n",
    "):\n",
    "    \"\"\"\n",
    "    - x_tick: major tick spacing in seconds (e.g., 5)\n",
    "    - ylim_max: top of y-axis (e.g., 0.5 to make it look 'half-height')\n",
    "    - decimate: keep every Nth bar (e.g., 2 or 3 to thin dense logs)\n",
    "    - stride_sec: bar width; if None we'll estimate from tsec diffs\n",
    "    \"\"\"\n",
    "    # map selected class names -> indices\n",
    "    name_to_idx = {c:i for i,c in enumerate(CONFIDENCE_COLS)}\n",
    "    sel_idx = [name_to_idx[c] for c in selected if c in name_to_idx]\n",
    "    if not sel_idx:\n",
    "        print(\"No classes selected.\")\n",
    "        return\n",
    "\n",
    "    # optional decimation to reduce density\n",
    "    if decimate and decimate > 1:\n",
    "        mask = np.zeros_like(tsec, dtype=bool)\n",
    "        mask[::decimate] = True\n",
    "        t = tsec[mask]\n",
    "        P = preds[mask]\n",
    "        T = targets[mask] if targets is not None else None\n",
    "    else:\n",
    "        t, P, T = tsec, preds, targets\n",
    "\n",
    "    # choose bar width: use stride (narrow) instead of full window\n",
    "    if stride_sec is None:\n",
    "        # median gap between centers is a good proxy for stride\n",
    "        diffs = np.diff(t)\n",
    "        stride_sec = float(np.median(diffs)) if len(diffs) else win_sec\n",
    "    bar_w = max(1e-3, stride_sec * 0.9)  # 90% of stride\n",
    "\n",
    "    plt.figure(figsize=(12, 4 + 0.4*len(sel_idx)))\n",
    "    bases = np.zeros_like(t)\n",
    "\n",
    "    for ci in sel_idx:\n",
    "        y = P[:, ci]\n",
    "        if stack:\n",
    "            bottom = bases.copy()\n",
    "            bases += y\n",
    "            plt.bar(t, y, width=bar_w, bottom=bottom, alpha=alpha,\n",
    "                    label=CONFIDENCE_COLS[ci], align='center')\n",
    "        else:\n",
    "            plt.bar(t, y, width=bar_w, alpha=alpha,\n",
    "                    label=CONFIDENCE_COLS[ci], align='center')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick))      # ← 5s ticks\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(_fmt_mmss))    # ← mm:ss\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick))\n",
    "    if xlim: plt.xlim(*xlim)\n",
    "    plt.ylim(0, float(ylim_max))                              # ← cap height\n",
    "    plt.xlabel(\"time (mm:ss)\")\n",
    "    plt.ylabel(\"confidence\")\n",
    "    plt.title(\"Predicted behavior confidence over time\")\n",
    "    plt.legend(ncol=2, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7233a81-04d3-4ae2-a61d-63b4d43bc36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e77b3301d9e4ebf939b443c1c1fd972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='.csv', description='Upload'), HBox(children=(SelectMultiple(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: upload a CSV, pick classes, click Run Inference.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ---------------------- USER LOG UPLOAD/UI ---------------------------------------------------------------------------\n",
    "uploader = FileUpload(accept='.csv', multiple=False)\n",
    "run_btn = Button(description=\"Run Inference\", button_style='success')\n",
    "classes_picker = SelectMultiple(\n",
    "    options=CONFIDENCE_COLS,\n",
    "    value=(\"cf_accel\",\"cf_brake\",\"cf_turn_left\",\"cf_turn_right\"),\n",
    "    description='Plot classes',\n",
    "    rows=8\n",
    ")\n",
    "alpha_slider = IntSlider(description='Alpha (%)', min=10, max=90, step=5, value=40)\n",
    "stack_cb = Checkbox(description='Stack bars', value=False)\n",
    "out = Output()\n",
    "\n",
    "\n",
    "\n",
    "def handle_run(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            val = uploader.value\n",
    "            if not val:\n",
    "                print(\"Upload a CSV first.\")\n",
    "                return\n",
    "\n",
    "            # compatibility for ipywidgets versions 7 and 8, dict vs tuple\n",
    "            if isinstance(val, dict):\n",
    "                item = next(iter(val.values()))\n",
    "                raw_bytes = item[\"content\"]\n",
    "                raw_name = item.get(\"metadata\", {}).get(\"name\", item.get(\"name\", \"uploaded.csv\"))\n",
    "            else:  # tuple/list in 8.x\n",
    "                item = val[0]\n",
    "                raw_bytes = item[\"content\"]\n",
    "                raw_name = item.get(\"name\", \"uploaded.csv\")\n",
    "\n",
    "            # Save uploaded file\n",
    "            up_dir = Path(\"uploads\")\n",
    "            up_dir.mkdir(exist_ok=True)\n",
    "            raw_file = up_dir / raw_name\n",
    "            raw_file.write_bytes(raw_bytes)\n",
    "            print(\"Uploaded:\", raw_file)\n",
    "\n",
    "            # Preprocess -> processed CSV\n",
    "            proc_csv = preprocess_user_log(str(raw_file))\n",
    "            print(\"Processed CSV:\", proc_csv)\n",
    "\n",
    "            # Build dataset and run inference\n",
    "            ds = build_dataset_from_csv(proc_csv)\n",
    "\n",
    "            tsec, win_sec, preds = run_inference_on_dataset(ds)\n",
    "            print(\"Windows:\", len(ds), \"| window_ms:\", ds.cfg.window_ms, \"| stride_ms:\", ds.cfg.stride_ms)\n",
    "\n",
    "            # Plot\n",
    "            alpha = alpha_slider.value / 100.0\n",
    "            selected = list(classes_picker.value)\n",
    "            plot_timeline_bars(tsec, win_sec, preds, None, CONFIDENCE_COLS, selected, alpha=alpha, stack=stack_cb.value,\n",
    "                           x_tick=5, ylim_max=1.0, decimate=2, stride_sec=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(\"ERROR:\", e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "run_btn.on_click(handle_run)\n",
    "display(VBox([uploader, HBox([classes_picker, VBox([alpha_slider, stack_cb, run_btn])]), out]))\n",
    "print(\"Ready: upload a CSV, pick classes, click Run Inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62395912-52b3-4682-859c-60e3e44f4c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f615ae8-3a3f-4ac2-9321-b5e215bd009a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395251c1-5490-412a-a75c-51284bc02556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VESC ML",
   "language": "python",
   "name": "vescml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
