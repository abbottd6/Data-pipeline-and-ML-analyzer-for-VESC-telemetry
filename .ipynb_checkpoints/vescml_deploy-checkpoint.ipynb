{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4628caaa-c3d6-483e-91bf-540827e437c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dayto\\AppData\\Local\\Temp\\ipykernel_24216\\912693871.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"best_model.pt\", map_location=DEVICE)\n"
     ]
    }
   ],
   "source": [
    "##%%\n",
    "# ---------------------- SETUP AND IMPORTS ----------------------------------------------------------------------------\n",
    "import torch\n",
    "from sympy.codegen.ast import continue_\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ipywidgets import FileUpload, Dropdown, SelectMultiple, Button, VBox, HBox, Output, IntSlider, Checkbox\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# import the dataset\n",
    "from model.vesc_dataset import VESCTimeSeriesDataset, VESCDatasetConfig, CONFIDENCE_COLS, FEATURE_COLS\n",
    "from preprocessing.prod_preprocessing import prod_load_log, prod_sample_rate_normalization\n",
    "from preprocessing.training_preprocessing import infer_log_date_from_filename\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model definition\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(c_in, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "        )\n",
    "        self.head = nn.Linear(64, c_out)\n",
    "\n",
    "    # x: (B, T, C)\n",
    "    def forward(self, x):\n",
    "        # translate to (B, C, T)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        h = self.net(x).squeeze(-1)\n",
    "        # (B, C_out) logits\n",
    "        return self.head(h)\n",
    "\n",
    "def load_normalization_and_model():\n",
    "    # load normalization stats from npz file from model training\n",
    "    NORM_STATS_FILE = np.load(\"norm_stats.npz\", allow_pickle=True)\n",
    "    NORM_MEAN = torch.from_numpy(NORM_STATS_FILE[\"mean\"]).to(DEVICE)\n",
    "    NORM_STD_DEV = torch.from_numpy(NORM_STATS_FILE[\"std\"]).to(DEVICE)\n",
    "    FEATURE_COLS = list(NORM_STATS_FILE[\"feature_cols\"])\n",
    "\n",
    "    # load trained model\n",
    "    c_in = len(FEATURE_COLS)\n",
    "    C_out = len(CONFIDENCE_COLS)\n",
    "    model = CNN(c_in, C_out).to(DEVICE)\n",
    "    state = torch.load(\"best_model.pt\", map_location=DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model, NORM_MEAN, NORM_STD_DEV, FEATURE_COLS\n",
    "\n",
    "MODEL, NORM_MEAN, NORM_STD_DEV, FEATURE_COLS = load_normalization_and_model()\n",
    "\n",
    "# normalize the batches to comparable value scale\n",
    "def normalize_batch(xb: torch.Tensor) -> torch.Tensor:\n",
    "    return (xb - NORM_MEAN) / NORM_STD_DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4bce58-2a7a-4614-983d-cd037e93994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%\n",
    "# ---------------------- LOG FILE PREPROCESSING -----------------------------------------------------------------------\n",
    "\n",
    "from preprocessing import prod_preprocessing\n",
    "\n",
    "# Input: path to a raw CSV uploaded by the user\n",
    "# Output: path to a single processed CSV (with your columns)\n",
    "def preprocess_user_log(raw_csv_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert a raw VESC Tool ride log into a CSV formatted for the machine learning model.\n",
    "    Return the path to the processed CSV.\n",
    "    \"\"\"\n",
    "    raw_path = Path(raw_csv_path)\n",
    "    # infer log date\n",
    "    ride_date = infer_log_date_from_filename(raw_csv_path)\n",
    "\n",
    "    # load the log\n",
    "    df = prod_load_log(raw_path, ride_date)\n",
    "    df_resampled =  prod_sample_rate_normalization(df)\n",
    "\n",
    "    out_dir = Path(\"tmp_processed\")\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    out_path = out_dir / f\"{raw_path.stem}_processed.csv\"\n",
    "    df_resampled.to_csv(out_path, index=False)\n",
    "    return str(out_path)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "##%%\n",
    "# ---------------------- MODEL INFERENCE  --------------------------------------------------------\n",
    "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
    "\n",
    "def build_dataset_from_csv(csv_path: str) -> VESCTimeSeriesDataset:\n",
    "    cfg = VESCDatasetConfig(\n",
    "        files=[csv_path],\n",
    "        feature_cols=None,\n",
    "        conf_cols=None,\n",
    "        sampling_hz=10.0,\n",
    "        window_ms=3000,\n",
    "        stride_ms=500,\n",
    "        min_valid_ratio=0.7,\n",
    "    )\n",
    "    ds = VESCTimeSeriesDataset(cfg)\n",
    "    # store the source path\n",
    "    ds._dfs[0].attrs[\"_source_path\"] = str(csv_path)\n",
    "    return ds\n",
    "\n",
    "def run_inference_on_dataset(ds: VESCTimeSeriesDataset):\n",
    "    # collect windows for file 0, sorted by start index\n",
    "    idxs = [(k, s, e) for k,(fi,s,e) in enumerate(ds._index) if fi == 0]\n",
    "    idxs.sort(key=lambda t: t[1])\n",
    "\n",
    "    df = ds._dfs[0]\n",
    "    tcol = ds.cfg.time_col if ds.cfg.time_col in df.columns else None\n",
    "\n",
    "    preds = []\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for k, s, e in idxs:\n",
    "            X, _ = ds[k]                              # (T,Cin), (Cout,)\n",
    "            xb = X.unsqueeze(0).to(DEVICE)            # (1,T,Cin)\n",
    "            pb = torch.sigmoid(MODEL(normalize_batch(xb))).cpu().numpy()[0]\n",
    "            preds.append(pb)\n",
    "            t_mid = float(df.loc[s:e-1, tcol].median()) if tcol else float(s)\n",
    "            times.append(t_mid)\n",
    "\n",
    "    preds = np.vstack(preds)     # (N, C_out)\n",
    "    times = np.asarray(times)    # (N,)\n",
    "    # normalize time to seconds starting at 0\n",
    "    t0 = times.min()\n",
    "    tsec = (times - t0) / 1000.0\n",
    "    # bar width (seconds)\n",
    "    win_sec = ds.window_steps / ds.cfg.sampling_hz\n",
    "    return tsec, win_sec, preds"
   ],
   "id": "cd2b932699912a13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T17:17:14.071326Z",
     "start_time": "2025-10-12T17:17:14.021327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##%%\n",
    "#----------------------- TIMELINE/GRAPH PLOTTING ------------------------------------------------------------------------\n",
    "def _fmt_mmss(x, pos=None):\n",
    "    m = int(x // 60)\n",
    "    s = int(x % 60)\n",
    "    return f\"{m}:{s:02d}\"\n",
    "\n",
    "def apply_behavior_conflict_suppression(probs_at_time: np.ndarray, behavior_class_names, conflict_groups):\n",
    "    \"\"\"\n",
    "    suppress mutually exclusive behaviors at each time step by keeping only the behavior with the highest\n",
    "    confidence within a conflict group at each time step. Zero out the other conflicting behaviors with lower\n",
    "    confidence.\n",
    "\n",
    "    :param probs_at_time: Y behavior confidence at time step\n",
    "    :param behavior_class_names: CONFIDENCE_COLS, the behavior classification names\n",
    "    :param conflict_groups: explicitly defined groups of conflicting behaviors, i.e., left and right turn, brake\n",
    "    and accelerate, that cannot occur simultaneously.\n",
    "\n",
    "    :return: a copy of the df with non-winning exclusive behaviors suppressed at each time step.\n",
    "    \"\"\"\n",
    "    # don't apply behavior suppression to behaviors that don't have exclusivity\n",
    "    if not conflict_groups:\n",
    "        return probs_at_time\n",
    "\n",
    "    name_to_idx = {behav_class:i for i, behav_class in enumerate(behavior_class_names)}\n",
    "    suppressed_behaviors = probs_at_time.copy()\n",
    "    for group in conflict_groups:\n",
    "        # convert behavior class names to column indices\n",
    "        group_col_idx = [name_to_idx[behav_class] for behav_class in group if behav_class in name_to_idx]\n",
    "        # if only one class in this group, then behavior suppression is not required\n",
    "        if len(group_col_idx) <= 1:\n",
    "            continue\n",
    "\n",
    "        # extract just the behaviors that belong to an exclusivity group\n",
    "        group_scores = suppressed_behaviors[group_col_idx]\n",
    "\n",
    "        # at each time step, find the index of the highest behavior score within the conflicting behaviors group\n",
    "        # winners_per_row is length num_steps with values in [0, group_size-1]\n",
    "        winners_per_row = np.argmax(group_scores, axis=1)\n",
    "\n",
    "        # build a boolean mask that is the same shape as the group_scores\n",
    "        # identifies highest confidence behavior within an exclusivity group and the behaviors to suppress\n",
    "        # True == winner at this row/col, False means a behavior to be suppressed\n",
    "        winner_mask = np.zeros_like(group_scores, dtype=bool)\n",
    "        winner_mask[np.arange(group_scores.shape[0]), winners_per_row] = True\n",
    "\n",
    "        # zero out the non-winner (False) scores\n",
    "        group_scores[~winner_mask] = 0.0\n",
    "\n",
    "        # write back into the behavior matrix\n",
    "        suppressed_behaviors[:, group_col_idx] = group_scores\n",
    "\n",
    "    return suppressed_behaviors\n",
    "\n",
    "\n",
    "def plot_timeline_bars(\n",
    "    tsec, win_sec, preds, targets, CONFIDENCE_COLS, selected,\n",
    "    alpha=0.35, stack=False,\n",
    "    xlim=None, x_tick=5, ylim_max=1.0, y_tick=0.1, decimate=2.0, stride_sec=None\n",
    "):\n",
    "    \"\"\"\n",
    "    - x_tick: major x-axis label spacing in seconds\n",
    "    - xlim: limit on x-axis maximum (log duration)\n",
    "    - y_tick: major y-axis label spacing in confidence magnitude (0 - 1)\n",
    "    - ylim_max: top of y-axis\n",
    "    - decimate: keep every Nth bar (reduces sample rate visualization to make graph decipherable)\n",
    "    - stride_sec: determines visual bar width on time-series graph\n",
    "    - selected: the behaviors selected by user for plotting\n",
    "    - alpha: transparency of bars\n",
    "    \"\"\"\n",
    "    # map selected class names to indices\n",
    "    name_to_idx = {c:i for i,c in enumerate(CONFIDENCE_COLS)}\n",
    "    sel_idx = [name_to_idx[c] for c in selected if c in name_to_idx]\n",
    "    if not sel_idx:\n",
    "        print(\"No classes selected.\")\n",
    "        return\n",
    "\n",
    "    # decimation to reduce sample density in plot\n",
    "    if decimate and decimate > 2.0:\n",
    "        mask = np.zeros_like(tsec, dtype=bool)\n",
    "        mask[::decimate] = True\n",
    "        t = tsec[mask]\n",
    "        P = preds[mask]\n",
    "        T = targets[mask] if targets is not None else None\n",
    "    else:\n",
    "        t, P, T = tsec, preds, targets\n",
    "\n",
    "    # visualization bar width calculated by stride_sec\n",
    "    if stride_sec is None:\n",
    "        # median gap between centers\n",
    "        diffs = np.diff(t)\n",
    "        stride_sec = float(np.median(diffs)) if len(diffs) else win_sec\n",
    "    bar_w = max(1e-3, stride_sec * 0.9)\n",
    "\n",
    "    plt.figure(figsize=(12, 4 + 0.4*len(sel_idx)))\n",
    "    bases = np.zeros_like(t)\n",
    "\n",
    "    for ci in sel_idx:\n",
    "        y = P[:, ci]\n",
    "        if stack:\n",
    "            bottom = bases.copy()\n",
    "            bases += y\n",
    "            plt.bar(t, y, width=bar_w, bottom=bottom, alpha=alpha,\n",
    "                    label=CONFIDENCE_COLS[ci], align='center')\n",
    "        else:\n",
    "            plt.bar(t, y, width=bar_w, alpha=alpha,\n",
    "                    label=CONFIDENCE_COLS[ci], align='center')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick))      # ← 5s ticks\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(_fmt_mmss))    # ← mm:ss\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick))\n",
    "    if xlim: plt.xlim(*xlim)\n",
    "    plt.ylim(0, float(ylim_max))                              # ← cap height\n",
    "    plt.xlabel(\"time (mm:ss)\")\n",
    "    plt.ylabel(\"confidence\")\n",
    "    plt.title(\"Predicted behavior confidence over time\")\n",
    "    plt.legend(ncol=2, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "ce23adb9574b9348",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m     s = \u001B[38;5;28mint\u001B[39m(x % \u001B[32m60\u001B[39m)\n\u001B[32m      6\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mm\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m02d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_apply_behavior_conflict_suppression\u001B[39m(probs_at_time: \u001B[43mnp\u001B[49m.ndarray, behav_class_names, conflict_groups):\n\u001B[32m      9\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m conflict_groups:\n\u001B[32m     10\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m probs_at_time\n",
      "\u001B[31mNameError\u001B[39m: name 'np' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7233a81-04d3-4ae2-a61d-63b4d43bc36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e77b3301d9e4ebf939b443c1c1fd972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='.csv', description='Upload'), HBox(children=(SelectMultiple(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: upload a CSV, pick classes, click Run Inference.\n"
     ]
    }
   ],
   "source": [
    "##%%\n",
    "# ---------------------- USER LOG UPLOAD/UI -----------------------------------------------------------------------------\n",
    "uploader = FileUpload(accept='.csv', multiple=False)\n",
    "run_btn = Button(description=\"Run Inference\", button_style='success')\n",
    "classes_picker = SelectMultiple(\n",
    "    options=CONFIDENCE_COLS,\n",
    "    value=(\"cf_accel\",\"cf_brake\",\"cf_turn_left\",\"cf_turn_right\"),\n",
    "    description='Plot classes',\n",
    "    rows=8\n",
    ")\n",
    "alpha_slider = IntSlider(description='Alpha (%)', min=10, max=90, step=5, value=40)\n",
    "stack_cb = Checkbox(description='Stack bars', value=False)\n",
    "out = Output()\n",
    "\n",
    "CONFLICT_GROUPS = [\n",
    "    [\"cf_turn_left\", \"cf_turn_right\"],\n",
    "    [\"cf_turn_left\", \"cf_carve_left\"],\n",
    "    [\"cf_turn_right\", \"cf_carve_right\"],\n",
    "    [\"cf_carve_left\", \"cf_carve_right\"],\n",
    "    [\"cf_accel\", \"cf_brake\"],\n",
    "    [\"cf_ascent\", \"cf_descent\"],\n",
    "    [\"cf_forward\", \"cf_reverse\"],\n",
    "]\n",
    "\n",
    "def handle_run(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            val = uploader.value\n",
    "            if not val:\n",
    "                print(\"Upload a CSV first.\")\n",
    "                return\n",
    "\n",
    "            # compatibility for ipywidgets versions 7 and 8, dict vs tuple\n",
    "            if isinstance(val, dict):\n",
    "                item = next(iter(val.values()))\n",
    "                raw_bytes = item[\"content\"]\n",
    "                raw_name = item.get(\"metadata\", {}).get(\"name\", item.get(\"name\", \"uploaded.csv\"))\n",
    "            else:  # tuple/list in 8.x\n",
    "                item = val[0]\n",
    "                raw_bytes = item[\"content\"]\n",
    "                raw_name = item.get(\"name\", \"uploaded.csv\")\n",
    "\n",
    "            # Save uploaded file\n",
    "            up_dir = Path(\"uploads\")\n",
    "            up_dir.mkdir(exist_ok=True)\n",
    "            raw_file = up_dir / raw_name\n",
    "            raw_file.write_bytes(raw_bytes)\n",
    "            print(\"Uploaded:\", raw_file)\n",
    "\n",
    "            # Preprocess -> processed CSV\n",
    "            proc_csv = preprocess_user_log(str(raw_file))\n",
    "            print(\"Processed CSV:\", proc_csv)\n",
    "\n",
    "            # Build dataset and run inference\n",
    "            ds = build_dataset_from_csv(proc_csv)\n",
    "\n",
    "            tsec, win_sec, preds = run_inference_on_dataset(ds)\n",
    "            print(\"Windows:\", len(ds), \"| window_ms:\", ds.cfg.window_ms, \"| stride_ms:\", ds.cfg.stride_ms)\n",
    "\n",
    "            # Plot\n",
    "            alpha = alpha_slider.value / 100.0\n",
    "            selected = list(classes_picker.value)\n",
    "            conf_suppressed_preds = apply_behavior_conflict_suppression(preds, CONFIDENCE_COLS, CONFLICT_GROUPS)\n",
    "            plot_timeline_bars(tsec, win_sec, conf_suppressed_preds, None, CONFIDENCE_COLS, selected, alpha=alpha, stack=stack_cb.value,\n",
    "                           x_tick=5, ylim_max=1.0, decimate=2, stride_sec=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(\"ERROR:\", e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "run_btn.on_click(handle_run)\n",
    "display(VBox([uploader, HBox([classes_picker, VBox([alpha_slider, stack_cb, run_btn])]), out]))\n",
    "print(\"Ready: upload a CSV, pick classes, click Run Inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62395912-52b3-4682-859c-60e3e44f4c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f615ae8-3a3f-4ac2-9321-b5e215bd009a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395251c1-5490-412a-a75c-51284bc02556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VESC ML",
   "language": "python",
   "name": "vescml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
